{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import glob\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_path):\n",
    "    # Define the feature description dictionary for parsing the TFRecord file\n",
    "    feature_description = {\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
    "    }\n",
    "\n",
    "    def _parse_tfrecord(example_proto):\n",
    "        # Parse a single example from the TFRecord file\n",
    "        return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "    # Create a dataset from the TFRecord file\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    dataset = dataset.map(_parse_tfrecord)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def evaluate_model(dataset, model, iou_threshold):\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "\n",
    "    for data in dataset:\n",
    "        image = data['image/encoded']\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        # Preprocess the image if required (e.g., resize, normalization)\n",
    "\n",
    "        # Make predictions with your object detection model\n",
    "        predictions = model.predict(image)\n",
    "\n",
    "        # Extract the predicted bounding boxes from the model's output if required\n",
    "\n",
    "        # Compare the predicted bounding boxes with the ground truth bounding boxes\n",
    "        iou_max = 0\n",
    "        for pred_box in predictions:\n",
    "            for i in range(data['image/object/bbox/xmin'].values.shape[0]):\n",
    "                gt_box = [\n",
    "                    data['image/object/bbox/xmin'].values[i],\n",
    "                    data['image/object/bbox/ymin'].values[i],\n",
    "                    data['image/object/bbox/xmax'].values[i],\n",
    "                    data['image/object/bbox/ymax'].values[i]\n",
    "                ]\n",
    "                iou = calculate_iou(gt_box, pred_box)\n",
    "                if iou > iou_max:\n",
    "                    iou_max = iou\n",
    "\n",
    "        # If the best IoU is above the threshold, count it as a true positive\n",
    "        if iou_max >= iou_threshold:\n",
    "            true_positives += 1\n",
    "        else:\n",
    "            false_positives += 1\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "\n",
    "    return precision\n",
    "\n",
    "# Example usage\n",
    "tfrecord_path = 'path/to/your/test_dataset.tfrecord'\n",
    "iou_threshold = 0.5\n",
    "model_path = 'path/to/your/model.pb'\n",
    "\n",
    "# Load the TFRecord dataset\n",
    "dataset = load_tfrecord_dataset(tfrecord_path)\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Evaluate the model on the dataset and calculate precision\n",
    "precision = evaluate_model(dataset, model, iou_threshold)\n",
    "print(\"Precision:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27976\\2212991894.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# load the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Bijaya\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors)\u001b[0m\n\u001b[0;32m    453\u001b[0m       ]\n\u001b[0;32m    454\u001b[0m       self._interpreter = (\n\u001b[1;32m--> 455\u001b[1;33m           _interpreter_wrapper.CreateWrapperFromFile(\n\u001b[0m\u001b[0;32m    456\u001b[0m               \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_resolver_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_op_registerers_by_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m               custom_op_registerers_by_func, experimental_preserve_all_tensors))\n",
      "\u001b[1;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# set paths and filenames\n",
    "model_path = 'E:\\Major_project_main\\Main\\inference_graph3\\saved_model\\saved_model.pb'\n",
    "test_data_dir = 'E:\\Major_project_main\\Data\\final_data\\test'\n",
    "test_csv_path = 'E:\\Major_project_main\\Data\\final_data\\test.csv'\n",
    "\n",
    "# set model input and output names\n",
    "input_name = 'input_1'\n",
    "output_names = ['efficientdet-d0/filtered_detections/map/TensorArrayStack/TensorArrayGatherV3:0']\n",
    "\n",
    "# load the model\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# load the test data CSV\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# create a list to hold the results\n",
    "results = []\n",
    "\n",
    "# loop through the test data and evaluate the model\n",
    "for index, row in test_df.iterrows():\n",
    "    # load the image\n",
    "    image_path = os.path.join(test_data_dir, row['name'])\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path, target_size=(512, 512))\n",
    "    input_data = np.expand_dims(tf.keras.preprocessing.image.img_to_array(image), axis=0)\n",
    "\n",
    "    # set the model input and invoke the interpreter\n",
    "    interpreter.set_tensor(interpreter.get_input_details()[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    # get the model output and post-process   \n",
    "    output_data = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])\n",
    "    detections = output_data[0]\n",
    "\n",
    "    # filter out low confidence detections\n",
    "    confidence_threshold = 0.5\n",
    "    detections = detections[detections[:, 4] >= confidence_threshold]\n",
    "\n",
    "    # convert from normalized coordinates to pixel coordinates\n",
    "    height, width, _ = image.shape\n",
    "    detections[:, 0] *= width\n",
    "    detections[:, 1] *= height\n",
    "    detections[:, 2] *= width\n",
    "    detections[:, 3] *= height\n",
    "\n",
    "    # convert to integers and add to the results list\n",
    "    for detection in detections:\n",
    "        results.append({\n",
    "            'image_id': row['name'],\n",
    "            'width': row['width'],\n",
    "            'height': row['height'],\n",
    "            'label': 'cricket ball',\n",
    "            'confidence': detection[4],\n",
    "            'xmin': int(detection[0]),\n",
    "            'ymin': int(detection[1]),\n",
    "            'xmax': int(detection[2]),\n",
    "            'ymax': int(detection[3]),\n",
    "        })\n",
    "\n",
    "# create a new DataFrame with the results and save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('E:\\Major_project_main\\Data\\final_data\\test\\results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
